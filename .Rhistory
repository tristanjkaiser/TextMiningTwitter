setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(twitteR)
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
prop64 <- searchTwitter("Proposition 64", since = "2016-11-09", until = "2016-11-10", n = 1000)
prop64 <- searchTwitter("#Prop64", since = "2016-11-09", until = "2016-11-10", n = 1000)
prop64 <- searchTwitter("#Prop64", since = "2016-01-09", until = "2016-11-10", n = 1000)
prop64 <- searchTwitter("#coffee", since = "2016-01-09", until = "2016-11-10", n = 1000)
prop64 <- searchTwitter("#coffee", since = "2016-11-17", until = "2016-11-18", n = 1000)
trumpTweets <- searchTwitter("#Trump", since = "2016-11-17", until = "2016-11-18", n = 1000)
library(tidyverse)
library(qdap)
install.packages("qdap")
trumpTweets_text = sapply(trumpTweets, function(x) x$getText())
trumpTweetsCorpus = Corpus(VectorSource(trumpTweetsText))
library(qdap)
library(tm)
trumpTweetsCorpus = Corpus(VectorSource(trumpTweetsText))
trumpTweetsText = sapply(trumpTweets, function(x) x$getText())
trumpTweetsCorpus = Corpus(VectorSource(trumpTweetsText))
tdm = TermDocumentMatrix(
trumpTweetsCorpus,
control = list(
removePunctuation = TRUE,
stopwords = c("Trump", stopwords("english")),
removeNumbers = TRUE, tolower = TRUE)
)
tdm = TermDocumentMatrix(
trumpTweetsCorpus,
control = list(
removePunctuation = TRUE,
stopwords = c("Trump", stopwords("english")),
removeNumbers = TRUE, toLower = TRUE)
)
trumpTweetsCorpus$text <- sapply(trumpTweetsCorpus$text,function(row) iconv(row, "latin1", "ASCII", sub=""))
tdm = TermDocumentMatrix(
trumpTweetsCorpus,
control = list(
removePunctuation = TRUE,
stopwords = c("Trump", stopwords("english")),
removeNumbers = TRUE, tolower = TRUE)
)
Sys.setlocale('LC_ALL',C')
tdm = TermDocumentMatrix(
trumpTweetsCorpus,
control = list(
removePunctuation = TRUE,
stopwords = c("Trump", stopwords("english")),
removeNumbers = TRUE, tolower = TRUE)
)
Sys.setlocale('LC_ALL','C')
tdm = TermDocumentMatrix(
trumpTweetsCorpus,
control = list(
removePunctuation = TRUE,
stopwords = c("Trump", stopwords("english")),
removeNumbers = TRUE, tolower = TRUE)
)
tdm = TermDocumentMatrix(
trumpTweetsCorpus,
control = list(
removePunctuation = TRUE,
stopwords = c("Trump", stopwords("english")),
removeNumbers = TRUE, TryToLower = TRUE)
)
tdm = TermDocumentMatrix(
trumpTweetsCorpus,
control = list(
removePunctuation = TRUE,
stopwords = c("Trump", stopwords("english")),
removeNumbers = TRUE, tryToLower = TRUE)
)
trumpTweetsCorpus <- sapply(trumpTweetsCorpus$text,function(row) iconv(row, "latin1", "ASCII", sub=""))
tdm = TermDocumentMatrix(
trumpTweetsCorpus,
control = list(
removePunctuation = TRUE,
stopwords = c("Trump", stopwords("english")),
removeNumbers = TRUE, tryToLower = TRUE)
)
trumpTweets <- searchTwitter("#Trump", since = "2016-11-17", until = "2016-11-18", n = 1000)
trumpTweetsText <- sapply(trumpTweets, function(x) x$getText()
)
trumpTweetsCorpus <- Corpus(VectorSource(trumpTweetsText))
library(stringi)
tdm = TermDocumentMatrix(
trumpTweetsCorpus,
control = list(
removePunctuation = TRUE,
stopwords = c("Trump", stopwords("english")),
removeNumbers = TRUE, stri_trans_tolower = TRUE)
)
tdm = TermDocumentMatrix(
trumpTweetsCorpus,
control = list(
removePunctuation = TRUE,
stopwords = c("Trump", stopwords("english")),
removeNumbers = TRUE)
)
tm_map(trumpTweetsCorpus, function(x) iconv(enc2utf8(x), sub = "byte"))
tm_map(trumpTweetsCorpus$text, function(x) iconv(enc2utf8(x), sub = "byte"))
usableText=str_replace_all(trumpTweetsCorpus$text,"[^[:graph:]]", " ")
install.packages("stringr")
library(stringr)
usableText=str_replace_all(trumpTweetsCorpus$text,"[^[:graph:]]", " ")
trumpTweetsCorpus$text <- str_replace_all(trumpTweetsCorpus$text,"[^[:graph:]]", " ")
tdm <- TermDocumentMatrix(
trumpTweetsCorpus,
control = list(
removePunctuation = TRUE,
stopwords = c("Trump", stopwords("english")),
removeNumbers = TRUE, tolower = TRUE)
)
trumpTweetsText <- twListToDF(trumpTweets)
trumpTweetsCorpus <- Corpus(VectorSource(trumpTweetsText))
tdm <- TermDocumentMatrix(
trumpTweetsCorpus,
control = list(
removePunctuation = TRUE,
stopwords = c("Trump", stopwords("english")),
removeNumbers = TRUE, tolower = TRUE)
)
trumpTweetsCorpus$text <- str_replace_all(trumpTweetsCorpus$text,"[^[:graph:]]", " ")
tdm <- TermDocumentMatrix(
trumpTweetsCorpus,
control = list(
removePunctuation = TRUE,
stopwords = c("Trump", stopwords("english")),
removeNumbers = TRUE, tolower = TRUE)
)
trumpTweets <- searchTwitter("#Trump", since = "2016-11-17", until = "2016-11-18", n = 1000)
trumpTweetsText <- twListToDF(trumpTweets)
#trumpTweetsText <- sapply(trumpTweets, function(x) x$getText())
trumpTweetsCorpus <- Corpus(VectorSource(trumpTweetsText))
print(trumpTweetsCorpus[[15]][1])
trumpTweetsText <- sapply(trumpTweets, function(x) x$getText())
trumpTweetsCorpus <- Corpus(VectorSource(trumpTweetsText))
print(trumpTweetsCorpus[[15]][1])
print(trumpTweetsCorpus[[1]][1])
print(trumpTweetsCorpus[[15]][2])
print(trumpTweetsCorpus[[15]][3])
print(trumpTweetsCorpus[[15]][1])
tm_map(trumpTweetsCorpus, removeNumbers)
print(trumpTweetsCorpus[[15]][1])
tm_map(trumpTweetsCorpus$text, removeNumbers)
removeWords(trumpTweetsCorpus, stopwords("en"))
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "Trump"))
corpus <- tm_map(corpus, content_transformer(tolower))
return(corpus)
}
trumpTweetsCorpus <- clean_corpus(trumpTweetsCorpus)
library(qdap)
install.packages("qdap")
library(qdap)
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "Trump"))
corpus <- tm_map(corpus, content_transformer(tolower))
return(corpus)
}
trumpTweetsCorpus <- clean_corpus(trumpTweetsCorpus)
term_count <- freq_terms(trumpTweetsCorpus, 10)
install.packages("rjava")
install.packages("rJava")
library(qdap)
install.packages("qdap")
library(qdap)
Sys.getenv("JAVA_HOME")
install.packages("rJava")
library(rjava)
library(Rjava)
library(rJava)
library(rJava)
options(java.home="C:\\Program Files (x86)\\Java\\jre1.8.0_111\\")
library(rJava)
install.packages("rJava")
library(rJava)
Sys.getenv("JAVA_HOME")
if (Sys.getenv("JAVA_HOME")!="")
Sys.setenv(JAVA_HOME="")
library(rJava)
library(rJava)
Sys.getenv("JAVA_HOME")
if (Sys.getenv("JAVA_HOME")!="")
Sys.setenv(JAVA_HOME="")
install.packages("rJava")
library(rJava)
options(java.home="C:\\Program Files\\Java\\jre1.8.0_111\\")
library(rJava)
library(qdap)
term_count <- freq_terms(trumpTweetsCorpus, 10)
View(term_count)
term_count <- freq_terms(trumpTweetsCorpus$text, 10)
tdm<-TermDocumentMatrix(trumpTweetsCorpus)
library(tm)
tdm<-TermDocumentMatrix(trumpTweetsCorpus)
tdm.tweets.m <- as.matrix(tdm)
term.freq<-rowSums(tdm.tweets.m)
freq.df<-data.frame(word=names(term.freq),frequency=term.freq)
View(freq.df)
install.packages("wordcloud")
library(tm)
library(qdap)
library(wordcloud)
tdm.v <- sort(rowSums(tdm.tweets.m),decreasing=TRUE)
tdm.df <- data.frame(word = names(tdm.v),freq=tdm.v)
set.seed(1)
wordcloud(tdm.df$word,tdm.df$freq,max.words=50, random.order=FALSE, colors=pal)
display.brewer.all()
pal <- brewer.pal(8, "Blues")
pal <- pal[-(1:2)]
set.seed(1)
wordcloud(tdm.df$word,tdm.df$freq,max.words=50, random.order=FALSE, colors=pal)
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "Trump", "trump"))
corpus <- tm_map(corpus, content_transformer(tolower))
return(corpus)
}
trumpTweetsCorpus <- clean_corpus(trumpTweetsCorpus)
up Term Document Matrix
tdm<-TermDocumentMatrix(trumpTweetsCorpus)
tdm.tweets.m <- as.matrix(tdm)
# Frequency Data Frame
term.freq <- rowSums(tdm.tweets.m)
freq.df<-data.frame(word=names(term.freq),frequency=term.freq)
#bigram token maker
#bigram.tokenizer <-function(x)
#   unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
tdm.v <- sort(rowSums(tdm.tweets.m),decreasing=TRUE)
tdm.df <- data.frame(word = names(tdm.v),freq=tdm.v)
display.brewer.all()
pal <- brewer.pal(8, "Blues")
pal <- pal[-(1:2)]
set.seed(1)
wordcloud(tdm.df$word,tdm.df$freq,max.words=50, random.order=FALSE, colors=pal)
tdm<-TermDocumentMatrix(trumpTweetsCorpus,, control=list(tokenize=bigram.tokenizer)))
tdm<-TermDocumentMatrix(trumpTweetsCorpus,, control=list(tokenize=bigram.tokenizer))
tdm<-TermDocumentMatrix(trumpTweetsCorpus, control=list(tokenize=bigram.tokenizer))
bigram.tokenizer <-function(x)
unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
tdm<-TermDocumentMatrix(trumpTweetsCorpus, control=list(tokenize=bigram.tokenizer))
options(stringsAsFactors = FALSE) #text strings will not be factors of categories
Sys.setlocale('LC_ALL','C') #some tweets are in different languages so you may get an error
bigram.tokenizer <- function(x)
unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
tdm<-TermDocumentMatrix(trumpTweetsCorpus, control=list(tokenize=bigram.tokenizer))
custom.reader <- readTabular(mapping=list(content="text", id="id"))
dd<-data.frame(id=text$id,text=trumTweetsText$text)
dd<-data.frame(id=trumpTweetsText$id,text=trumTweetsText$text)
dd<-data.frame(id=trumpTweets$id,text=trumTweets$text)
dd<-data.frame(id=trumpTweets$id,text=trumpTweets$text)
custom.reader <- readTabular(mapping=list(content="text", id="id"))
trumpTweetsCorpus <- VCorpus(DataframeSource(dd), readerControl=list(reader=custom.reader))
trumpTweetsCorpus <- clean_corpus(trumpTweetsCorpus)
bigram.tokenizer <- function(x)
unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
tdm<-TermDocumentMatrix(trumpTweetsCorpus, control=list(tokenize=bigram.tokenizer))
tdm.tweets.m <- as.matrix(tdm)
term.freq <- rowSums(tdm.tweets.m)
freq.df<-data.frame(word=names(term.freq),frequency=term.freq)
tdm.v <- sort(rowSums(tdm.tweets.m),decreasing=TRUE)
tdm.df <- data.frame(word = names(tdm.v),freq=tdm.v)
wordcloud(tdm.df$word,tdm.df$freq,max.words=50, random.order=FALSE, colors=pal)
tdm.m[1000:1005,1:10]
tdm.M <- as.matrix(tdm)
tdm.m <- as.matrix(tdm)
tdm.m[1000:1005,1:10]
tdm.m[1000:1005,1:10]
tdm.m <- as.matrix(tdm)
term.freq <- rowSums(tdm.tweets.m)
freq.df<-data.frame(word=names(term.freq),frequency=term.freq)
tdm.v <- sort(rowSums(tdm.m),decreasing=TRUE)
tdm.df <- data.frame(word = names(tdm.v),freq=tdm.v)
wordcloud(tdm.df$word,tdm.df$freq,max.words=50, random.order=FALSE, colors=pal)
tdm<-TermDocumentMatrix(trumpTweetsCorpus, control=list(tokenize=bigram.tokenizer))
tdm.m <- as.matrix(tdm)
tdm.m[1000:1005,1:10]
View(tdm.m)
trumpTweetsCorpus <- VCorpus(DataframeSource(dd), readerControl=list(reader=custom.reader))
trumpTweets <- searchTwitter("#Trump", since = "2016-11-17", until = "2016-11-18", n = 1000)
library(twitteR)
View(tdm.tweets.m)
dd<-data.frame(id = trumpTweets$id,text = trumpTweets$text)
View(dd)
dd<-as.data.frame(id = trumpTweets$id, text = trumpTweets$text)
install.packages("Rcurl")
install.packages("RCurl")
install.packages("RCurl")
df <- do.call("rbind", lapply(trumpTweets, as.data.frame))
library(RCurl)
install.packages("twListToDF ")
install.packages("twListToDF")
df <- do.call("rbind", lapply(trumpTweets, as.data.frame))
library(twitteR)
library(tm)
library(qdap)
library(wordcloud)
df <- do.call("rbind", lapply(trumpTweets, as.data.frame))
View(df)
trumpTweets <- do.call("rbind", lapply(trumpTweets, as.data.frame))
dd <-data.frame(id = trumpTweets$id, text = trumpTweets$text)
custom.reader <- readTabular(mapping=list(content="text", id="id"))
trumpTweetsCorpus <- VCorpus(DataframeSource(dd), readerControl=list(reader=custom.reader))
trumpTweetsCorpus <- clean_corpus(trumpTweetsCorpus)
bigram.tokenizer <- function(x)
unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
tdm <- TermDocumentMatrix(trumpTweetsCorpus, control=list(tokenize=bigram.tokenizer))
tdm.m <- as.matrix(tdm)
tdm.m[1000:1005,1:10]
term.freq <- rowSums(tdm.tweets.m)
freq.df<-data.frame(word=names(term.freq),frequency=term.freq)
tdm.v <- sort(rowSums(tdm.m),decreasing=TRUE)
tdm.df <- data.frame(word = names(tdm.v),freq=tdm.v)
display.brewer.all()
pal <- brewer.pal(8, "Blues")
pal <- pal[-(1:2)]
set.seed(1)
wordcloud(tdm.df$word,tdm.df$freq,max.words=50, random.order=FALSE, colors=pal)
etsText))
# Clean corpus
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "Trump", "trump", "amp"))
corpus <- tm_map(corpus, content_transformer(tolower))
return(corpus)
}
# Set up tweets as a dataframe
trumpTweets <- do.call("rbind", lapply(trumpTweets, as.data.frame))
dd <-data.frame(id = trumpTweets$id, text = trumpTweets$text)
custom.reader <- readTabular(mapping=list(content="text", id="id"))
trumpTweetsCorpus <- VCorpus(DataframeSource(dd), readerControl=list(reader=custom.reader))
trumpTweetsCorpus <- clean_corpus(trumpTweetsCorpus)
# bigram token maker
bigram.tokenizer <- function(x)
unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
# Set up Term Document Matrix
tdm <- TermDocumentMatrix(trumpTweetsCorpus, control=list(tokenize=bigram.tokenizer))
tdm.m <- as.matrix(tdm)
tdm.m[1000:1005,1:10]
# Frequency Data Frame
term.freq <- rowSums(tdm.tweets.m)
freq.df<-data.frame(word=names(term.freq),frequency=term.freq)
tdm.v <- sort(rowSums(tdm.m),decreasing=TRUE)
tdm.df <- data.frame(word = names(tdm.v),freq=tdm.v)
display.brewer.all()
pal <- brewer.pal(8, "Blues")
pal <- pal[-(1:2)]
set.seed(1)
wordcloud(tdm.df$word,tdm.df$freq,max.words=50, random.order=FALSE, colors=pal)
trumpTweets <- do.call("rbind", lapply(trumpTweets, as.data.frame))
dd <-data.frame(id = trumpTweets$id, text = trumpTweets$text)
custom.reader <- readTabular(mapping=list(content="text", id="id"))
trumpTweetsCorpus <- VCorpus(DataframeSource(dd), readerControl=list(reader=custom.reader))
trumpTweetsCorpus <- clean_corpus(trumpTweetsCorpus)
bigram.tokenizer <- function(x)
unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
tdm <- TermDocumentMatrix(trumpTweetsCorpus, control=list(tokenize=bigram.tokenizer))
tdm.m <- as.matrix(tdm)
tdm.m[1000:1005,1:10]
trumpTweets <- searchTwitter("#Trump", since = "2016-11-17", until = "2016-11-18", n = 1000)
# Twitter Authentication
api_key <- 	"zCiXSFqLhBiwKZJQO7Mo1ftb4"
api_secret <-	"L4JFpxGa77BSZi5f9sdsslJTBvC7Z5X6dxrGXPWfCs9tasvDvD"
access_token <- "1477661306-cCgdZ2BkN7f0u5UCt7R4yJ6zcdhLPbQ6bLbY48G"
access_token_secret <- "g3VOz6tv0WR0wgSC09VsBErKBCmRWOWAH0O3VykZDHgxK"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
twitter.Auth <- c(api_key = "zCiXSFqLhBiwKZJQO7Mo1ftb4",
api_secret =	"L4JFpxGa77BSZi5f9sdsslJTBvC7Z5X6dxrGXPWfCs9tasvDvD",
access_token = "1477661306-cCgdZ2BkN7f0u5UCt7R4yJ6zcdhLPbQ6bLbY48G",
access_token_secret = "g3VOz6tv0WR0wgSC09VsBErKBCmRWOWAH0O3VykZDHgxK")
options(stringsAsFactors = FALSE)
Sys.setlocale('LC_ALL','C')
trumpTweets <- searchTwitter("#Trump", since = "2016-11-17", until = "2016-11-18", n = 1000)
twitter.Auth <- c(api_key = "zCiXSFqLhBiwKZJQO7Mo1ftb4",
api_secret =	"L4JFpxGa77BSZi5f9sdsslJTBvC7Z5X6dxrGXPWfCs9tasvDvD",
access_token = "1477661306-cCgdZ2BkN7f0u5UCt7R4yJ6zcdhLPbQ6bLbY48G",
access_token_secret = "g3VOz6tv0WR0wgSC09VsBErKBCmRWOWAH0O3VykZDHgxK")
setup_twitter_oauth(twitter.Auth)
# Functions ---------------------------------------------------
# Function to clean corpus
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "Trump", "trump", "amp"))
corpus <- tm_map(corpus, content_transformer(tolower))
return(corpus)
}
# Function for bigram token maker
bigram.tokenizer <- function(x)
unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
# Additional Settings -----------------------------------------
# Set so text strings will not be factors of categories
options(stringsAsFactors = FALSE)
# Prevent errors with tweets in different languages
Sys.setlocale('LC_ALL','C')
# Analysis ----------------------------------------------------
# Gather Tweets
trumpTweets <- searchTwitter("#Trump", since = "2016-11-17", until = "2016-11-18", n = 1000)
# Set up tweets as a dataframe, and reduce to only id & text
df.trumpTweets <- do.call("rbind", lapply(trumpTweets, as.data.frame))
df.reduced.trumpTweets <- data.frame(id = df.trumpTweets$id, text = df.trumpTweets$text)
custom.reader <- readTabular(mapping=list(content="text", id="id"))
corpus.trumpTweets <- VCorpus(DataframeSource(df.reduced.trumpTweets), readerControl=list(reader=custom.reader))
corpus.trumpTweets <- clean_corpus(corpus.trumpTweets)
# Set up Term Document Matrix & get freqency of bigram terms
tdm.TrumpTweets <- TermDocumentMatrix(corpus.trumpTweets, control = list(tokenize = bigram.tokenizer))
tdm.m.trumpTweets <- as.matrix(tdm.TrumpTweets)
tdm.freq.trumpTweets <- sort(rowSums(tdm.m.trumpTweets), decreasing = TRUE)
tdm.df.trumpTweets <- data.frame(word = names(tdm.freq.trumpTweets), freq = tdm.freq.trumpTweets)
#display.brewer.all()
#pal <- brewer.pal(8, "Blues")
#pal <- pal[-(1:2)]
set.seed(1)
wordcloud(tdm.df.trumpTweets$word,tdm.df.trumpTweets$freq,max.words=50, random.order=FALSE, colors="Blues")
display.brewer.all()
pal <- brewer.pal(8, "Blues")
pal <- pal[-(1:2)]
wordcloud(tdm.df.trumpTweets$word,tdm.df.trumpTweets$freq,max.words=50, random.order=FALSE, colors=pal)
warnings()
library(twitteR)
library(tm)
library(qdap)
library(wordcloud)
library(RCurl)
# Twitter Authentication --------------------------------------
twitter.Auth <- c(api_key = "CRDsansBY3AzDrfDSjl4YeR9m",
api_secret =
"mjpQq0Tk4VDgukoYBhlFqIP4uCbsRbiNjtV6qoT4jTyRJp24oE",
access_token = "1477661306-
cCgdZ2BkN7f0u5UCt7R4yJ6zcdhLPbQ6bLbY48G",
access_token_secret =
"g3VOz6tv0WR0wgSC09VsBErKBCmRWOWAH0O3VykZDHgxK")
setup_twitter_oauth(twitter.Auth)
# Functions ---------------------------------------------------
# Function to clean corpus
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "Trump", "trump", "amp"))
corpus <- tm_map(corpus, content_transformer(tolower))
return(corpus)
}
# Function for bigram token maker
bigram.tokenizer <- function(x)
unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
# Additional Settings -----------------------------------------
# Set so text strings will not be factors of categories
options(stringsAsFactors = FALSE)
# Prevent errors with tweets in different languages
Sys.setlocale('LC_ALL','C')
# Analysis ----------------------------------------------------
# Gather Tweets
trumpTweets <- searchTwitter("#Trump", since = "2016-11-18", until = "2016-11-19", n = 1000)
# Set up tweets as a dataframe, and reduce to only id & text
df.trumpTweets <- do.call("rbind", lapply(trumpTweets, as.data.frame))
df.reduced.trumpTweets <- data.frame(id = df.trumpTweets$id, text = df.trumpTweets$text)
custom.reader <- readTabular(mapping=list(content="text", id="id"))
corpus.trumpTweets <- VCorpus(DataframeSource(df.reduced.trumpTweets), readerControl=list(reader=custom.reader))
corpus.trumpTweets <- clean_corpus(corpus.trumpTweets)
# Set up Term Document Matrix & get freqency of bigram terms
tdm.trumpTweets <- TermDocumentMatrix(corpus.trumpTweets, control = list(tokenize = bigram.tokenizer))
tdm.m.trumpTweets <- as.matrix(tdm.trumpTweets)
tdm.freq.trumpTweets <- sort(rowSums(tdm.m.trumpTweets), decreasing = TRUE)
tdm.df.trumpTweets <- data.frame(word = names(tdm.freq.trumpTweets), freq = tdm.freq.trumpTweets)
display.brewer.all()
pal <- brewer.pal(8, "Blues")
pal <- pal[-(1:2)]
set.seed(1)
wordcloud(tdm.df.trumpTweets$word,tdm.df.trumpTweets$freq,max.words=50, random.order=FALSE, colors=pal)
twitter.Auth <- c(api_key = "CRDsansBY3AzDrfDSjl4YeR9m",
api_secret =
"mjpQq0Tk4VDgukoYBhlFqIP4uCbsRbiNjtV6qoT4jTyRJp24oE",
access_token = "1477661306-
cCgdZ2BkN7f0u5UCt7R4yJ6zcdhLPbQ6bLbY48G",
access_token_secret =
"g3VOz6tv0WR0wgSC09VsBErKBCmRWOWAH0O3VykZDHgxK")
setup_twitter_oauth(twitter.Auth)
twitter.Auth <- c(api_key = "CRDsansBY3AzDrfDSjl4YeR9m",
api_secret = "mjpQq0Tk4VDgukoYBhlFqIP4uCbsRbiNjtV6qoT4jTyRJp24oE",
access_token = "1477661306-cCgdZ2BkN7f0u5UCt7R4yJ6zcdhLPbQ6bLbY48G",
access_token_secret = "g3VOz6tv0WR0wgSC09VsBErKBCmRWOWAH0O3VykZDHgxK")
setup_twitter_oauth(twitter.Auth)
twitter.Auth <- c(api_key = "CRDsansBY3AzDrfDSjl4YeR9m",
api_secret = "mjpQq0Tk4VDgukoYBhlFqIP4uCbsRbiNjtV6qoT4jTyRJp24oE",
access_token = "1477661306-cCgdZ2BkN7f0u5UCt7R4yJ6zcdhLPbQ6bLbY48G",
access_token_secret = "g3VOz6tv0WR0wgSC09VsBErKBCmRWOWAH0O3VykZDHgxK")
setup_twitter_oauth(twitter.Auth)
library(httr)
setup_twitter_oauth(twitter.Auth)
install.packages("httr")
setup_twitter_oauth(twitter.Auth)
library(httr)
library(twitteR)
twitter.Auth <- c(api_key = "CRDsansBY3AzDrfDSjl4YeR9m",
api_secret = "mjpQq0Tk4VDgukoYBhlFqIP4uCbsRbiNjtV6qoT4jTyRJp24oE",
access_token = "1477661306-cCgdZ2BkN7f0u5UCt7R4yJ6zcdhLPbQ6bLbY48G",
access_token_secret = "g3VOz6tv0WR0wgSC09VsBErKBCmRWOWAH0O3VykZDHgxK")
setup_twitter_oauth(twitter.Auth)
library(httr)
twitter.Auth <- c(api_key = "CRDsansBY3AzDrfDSjl4YeR9m",
api_secret = "mjpQq0Tk4VDgukoYBhlFqIP4uCbsRbiNjtV6qoT4jTyRJp24oE",
access_token = "1477661306-cCgdZ2BkN7f0u5UCt7R4yJ6zcdhLPbQ6bLbY48G",
access_token_secret = "g3VOz6tv0WR0wgSC09VsBErKBCmRWOWAH0O3VykZDHgxK")
setup_twitter_oauth(twitter.Auth)
